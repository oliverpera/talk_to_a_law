{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ChromaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# REPLICATE_API_TOKEN = os.getenv(\"REPLICATE_API_TOKEN\")\n",
    "HUGGINGFACE_API_KEY = os.getenv(\"HUGGINGFACE_API_KEY\")\n",
    "TEXT_FILES_FOLDER = \"../resources/Wissensquellen\"\n",
    "SPLITS_PATH = \"../resources/splits/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Get Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core import documents\n",
    "import pandas as pd\n",
    "\n",
    "def create_document(chunk):\n",
    "    page_content = chunk\n",
    "    # metadata = {\n",
    "    #     \"splitter\": ,\n",
    "    #     \"\",}\n",
    "    doc = documents.Document(\n",
    "        page_content=page_content,\n",
    "        # metadata=metadata,\n",
    "    )\n",
    "    return doc\n",
    "# len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Embedding Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb.utils.embedding_functions as embedding_functions\n",
    "from chromadb import Documents, EmbeddingFunction, Embeddings\n",
    "# import replicate\n",
    "import spacy\n",
    "\n",
    "huggingface_ef = embedding_functions.HuggingFaceEmbeddingFunction(\n",
    "    api_key=HUGGINGFACE_API_KEY,\n",
    "    # model_name=\"sentence-transformers/all-MiniLM-L6-v2\"  # das ist der default\n",
    ")\n",
    "\n",
    "# openai_embeddings = \n",
    "\n",
    "# replicate_embeddings = \n",
    "\n",
    "class SpacyEmbeddingsFunction(EmbeddingFunction):\n",
    "    def __call__(self, input: Documents) -> Embeddings:\n",
    "        nlp = spacy.load(\"de_core_news_sm\") # md , lg , trf (bert-base-german-cased)\n",
    "        embeddings = [nlp(document).vector.tolist() for document in input]\n",
    "        return embeddings\n",
    "spacy_ef = SpacyEmbeddingsFunction()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Chroma Client and Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding 3724 Chunks from CELEX_02013L0036-20220101_DE_TXT.json to collection char_splitter_128_o0 in 4 batches.\n",
      "    Batch '0 - 1000' complete\n",
      "    Batch '1000 - 2000' complete\n",
      "    Batch '2000 - 3000' complete\n",
      "    Batch '3000 - 3724' complete\n",
      "Success - length of collection char_splitter_128_o0 is 3724\n",
      "Adding 16041 Chunks from CELEX_02013R0575-20230628_DE_TXT.json to collection char_splitter_128_o0 in 17 batches.\n",
      "    Batch '0 - 1000' complete\n",
      "    Batch '1000 - 2000' complete\n",
      "    Batch '2000 - 3000' complete\n",
      "    Batch '3000 - 4000' complete\n",
      "    Batch '4000 - 5000' complete\n",
      "    Batch '5000 - 6000' complete\n",
      "    Batch '6000 - 7000' complete\n",
      "    Batch '7000 - 8000' complete\n",
      "    Batch '8000 - 9000' complete\n",
      "    Batch '9000 - 10000' complete\n",
      "    Batch '10000 - 11000' complete\n",
      "    Batch '11000 - 12000' complete\n",
      "    Batch '12000 - 13000' complete\n",
      "    Batch '13000 - 14000' complete\n",
      "    Batch '14000 - 15000' complete\n",
      "    Batch '15000 - 16000' complete\n",
      "    Batch '16000 - 16041' complete\n",
      "Success - length of collection char_splitter_128_o0 is 19765\n",
      "Adding 6917 Chunks from KWG.json to collection char_splitter_128_o0 in 7 batches.\n",
      "    Batch '0 - 1000' complete\n",
      "    Batch '1000 - 2000' complete\n",
      "    Batch '2000 - 3000' complete\n",
      "    Batch '3000 - 4000' complete\n",
      "    Batch '4000 - 5000' complete\n",
      "    Batch '5000 - 6000' complete\n",
      "    Batch '6000 - 6917' complete\n",
      "Success - length of collection char_splitter_128_o0 is 26682\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "\n",
    "chroma_client = chromadb.PersistentClient(path=\"../resources/chromadb\")\n",
    "\n",
    "def create_collection(split_folder):\n",
    "    file_names = os.listdir(SPLITS_PATH + split_folder)\n",
    "    \n",
    "    collection = chroma_client.get_or_create_collection(\n",
    "        name=split_folder[:-1],\n",
    "        embedding_function=spacy_ef,\n",
    "        # metadata={\"hnsw:space\": \"cosine\"} # \"l2\" (default: squared L2 norm), \"ip\" or \"cosine\"\n",
    "        )\n",
    "\n",
    "    for file in file_names:\n",
    "        file_path = SPLITS_PATH + split_folder + file\n",
    "        df = pd.read_json(file_path)\n",
    "        documents_ = df['splits'].to_list()\n",
    "        ids = [file[:-4] + \"#\" + str(i) for i in range(0, len(documents_))]\n",
    "        metadata = [{\"file\": file[:-4]} for i in range(0, len(documents_))] # doesn`t work because of filename\n",
    "        \n",
    "        number_documents = len(documents_)\n",
    "        batchsize = 1000 # need to add in batches as batchsize cap is 5461 \n",
    "        batch_indexes = [i * batchsize for i in range (1, number_documents//batchsize + 1)]\n",
    "        batch_indexes.append(number_documents)\n",
    "        current = 0\n",
    "        print(f\"Adding {len(documents_)} Chunks from {file} to collection {collection.name} in {len(batch_indexes)} batches.\")\n",
    "        for index in batch_indexes:\n",
    "            documents_batch = documents_[current:index]\n",
    "            ids_batch = ids[current:index]\n",
    "            metadata_batch = metadata[current:index]\n",
    "            collection.add(\n",
    "                ids=ids_batch,\n",
    "                documents=documents_batch,\n",
    "                metadatas=metadata_batch\n",
    "                )\n",
    "            print(f\"    Batch '{current} - {index}' complete\")\n",
    "            current = index\n",
    "\n",
    "        print(f\"Success - length of collection {collection.name} is {collection.count()}\")\n",
    "\n",
    "split_folder = SPLITS_PATH + \"char_splitter_128_o0/\"\n",
    "create_collection(\"char_splitter_128_o0/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCRIPT FINISH, HERE ONLY TESTING FOR RETRIEVAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Add of existing embedding ID: 1\n",
      "Add of existing embedding ID: 2\n",
      "Add of existing embedding ID: 3\n",
      "Insert of existing embedding ID: 1\n",
      "Insert of existing embedding ID: 2\n",
      "Insert of existing embedding ID: 3\n"
     ]
    }
   ],
   "source": [
    "# collection = chroma_client.get_or_create_collection(\n",
    "#     name=\"test\",\n",
    "#     embedding_function=SpacyEmbeddingsFunction(),\n",
    "#     # metadata={\"hnsw:space\": \"cosine\"} # \"l2\" (default: squared L2 norm), \"ip\" or \"cosine\"\n",
    "#     )\n",
    "\n",
    "# collection = chroma_client.get_or_create_collection(\n",
    "#     name=\"first_collection\",\n",
    "#     embedding_function=huggingface_ef,\n",
    "#     # metadata={\"hnsw:space\": \"cosine\"} # \"l2\" (default: squared L2 norm), \"ip\" or \"cosine\"\n",
    "#     )\n",
    "\n",
    "# collection.add(\n",
    "#     ids=[\"1\", \"2\", \"3\"],\n",
    "#     documents=[\"Apfel\", \"Fahrzeug\", \"Rechtssprechung\"],\n",
    "#     # metadatas=[{},{}]\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collection.peek(0)\n",
    "# collection.count()\n",
    "# collection.modify(name=\"new_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collection.query(\n",
    "#     query_embeddings=[], # embedded question / part of question # HERE: PREFORMULATE ANSWER, EMBED ANSWER, RETRIEVE REAL KNOWLEDGE ?!? # needs to be the same dimension as embedded vectors in db\n",
    "#     query_texts=[\"Obst\"], # ALTERNATIVE THAN QUERYING WITH EMBEDDINGS -> CHROMA WILL AUTOMATICALLY EMBED USING EMBEDDING FUNCTION OF COLLECTION\n",
    "#     n_results=1, # number of docs to retrieve\n",
    "#     where={\"metadata_field\": \"is_equal_to_this\"}, # filter metadata\n",
    "#     where_document={\"$contains\": \"search_string\"} # filter for hard words / regexes etc.\n",
    "#     include=[\"documents\"], specify which data to return (embeddings is excluded by default)\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collection.get( # when wanting to not query with embeddings but only retrieve by id or so\n",
    "#     # ids=[], \n",
    "#     # where={,}\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # more info: https://docs.trychroma.com/usage-guide"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
